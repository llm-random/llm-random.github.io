[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/neuron_recycling/index.html",
    "href": "posts/neuron_recycling/index.html",
    "title": "Neuron Recycling",
    "section": "",
    "text": "Sparse neural networks have garnered attention due to their theoretical promise of lowered computational demands and memory savings. However, to this date, the theoretical gains have largely failed to materialize due to the lack of hardware support for this kind of models. In this work, we explore the idea of neuron recycling which is inspired by pruning - a method often employed to induce sparsity in neural networks. We also present lessons we have learned along the way."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To Our Blog",
    "section": "",
    "text": "This is the first post in our blog.\nWelcome!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "llm-random",
    "section": "",
    "text": "Neuron Recycling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2023\n\n\nJakub Krajewski, Maciej Pióro, Sebastian Jaszczur, Marek Cygan\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To Our Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2023\n\n\nMaciej Pióro\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#baseline-reinitialization",
    "href": "posts/neuron_recycling/index.html#baseline-reinitialization",
    "title": "Neuron Recycling",
    "section": "Baseline reinitialization",
    "text": "Baseline reinitialization\nThe most straightforward reinitialization scheme is to sample the weights of the reinitialized neurons from the initial distribution. After examining the performance of this solution, we could not see any difference between recycling and vanilla training. As a sanity check, we have examined the histogram presenting the number of times each neuron was recycled, discovering that the same small subset of neurons was being reinitialized over and over during training. As we have seen , on average magnitude of neurons grows throughout the training. Therefore, the newly sampled neurons have, on average, lower magnitudes than non-recycled neurons and are unable to catch up to non-recycled neurons before another selection phase. Thus, the recycled neurons are caught up in a vicious cycle in which they are always recycled before achieving high magnitude.\n\n&lt;spróbować zrobić diagram z vicious cycle&gt;\nAnother thing we tried to make reinitialization work was Immunity. The idea here is to encourage diverse recycling by making each recycled neuron immune to further recycling for some predefined number of steps. We hypothesized that a reinitialized neuron needs some time to grow, but in our initial setting, the neuron is recycled before enough growth happens, keeping the smaller neurons in a vicious cycle of periodically reoccurring reinitialization. Unfortunately, in our experiments, the reinitialized neurons failed to grow even if given immunity. At the same time immunity of the small neurons lead to recycling of the large neurons, hurting the model’s performance.\n&lt;graph in which initial recycling are not visible, but later once show it hurts performance&gt;\nAt this point, we hypothesized that coming back to the initial distribution may not be the optimal choice, as weights of the neurons evolve while they are trained. The next idea we wanted to experiment with was simply sampling from the distribution that occurred across the entire layer at any given moment. Our approach was straightforward: we randomly selected from all the weights in the entire matrix. Here again, we noted the impact of our technique, but it was only when we conducted such intensive recycling that performance deteriorated. ^ Tu opisać reinicjalizację z dystrybucją z momentu recyklingu\n\nAt this stage of our project, we gained interest in the topic of growing neural networks. Intuitively, this problem has a similar part, in which we want to add new neurons or weights. In the case of Large Language Models, the topic is mentioned in [Gopher]. The authors describe that for their experiments, copying existing neurons was the best strategy. We have also tried this strategy, but without positive results.\nStarając się wyjaśnić nasze dotychczasowe problemy, zwróciliśmy uwagę na dyskretną naturę naszej techniki, as opposed to the continuous landscape of training/optimizers. To change this, we have modified our strategy to gradually change the value by linear interpolation, according to the rule\n&lt;latex ze wzorkiem; może jakiś plot z naszymi górkami&gt;,\nwhere was frozen and trainable. We have noticed that this way we were able to make training loss dynamics smoother, but still without any positive effect.\nIn general, we couldn’t beat the baseline in terms of performance."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#baseline-recycling",
    "href": "posts/neuron_recycling/index.html#baseline-recycling",
    "title": "Neuron Recycling",
    "section": "Baseline recycling",
    "text": "Baseline recycling\nThe most straightforward reinitialization scheme is to sample the weights of the reinitialized neurons from the initial distribution. After examining the performance of this solution, we could not see any difference between recycling and vanilla training. As a sanity check, we have examined the histogram presenting the number of times each neuron was recycled, discovering that the same small subset of neurons was being reinitialized over and over during training. As we have seen , on average magnitude of neurons grows throughout the training. Therefore, the newly sampled neurons have, on average, lower magnitudes than non-recycled neurons and are unable to catch up to non-recycled neurons before another selection phase. Thus, the recycled neurons are caught up in a vicious cycle in which they are always recycled before achieving high magnitude.\n\n\n\n\n\n\n                                                    \n\n\nFigure 1: Figure description\n\n\n\n\n\n\n                                                    \n\n\n&lt;spróbować zrobić diagram z vicious cycle&gt;"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#section",
    "href": "posts/neuron_recycling/index.html#section",
    "title": "Neuron Recycling",
    "section": "",
    "text": "&lt;graph in which initial recycling are not visible, but later once show it hurts performance&gt;\nAt this point, we hypothesized that coming back to the initial distribution may not be the optimal choice, as weights of the neurons evolve while they are trained. The next idea we wanted to experiment with was simply sampling from the distribution that occurred across the entire layer at any given moment. Our approach was straightforward: we randomly selected from all the weights in the entire matrix. Here again, we noted the impact of our technique, but it was only when we conducted such intensive recycling that performance deteriorated. ^ Tu opisać reinicjalizację z dystrybucją z momentu recyklingu\n\nAt this stage of our project, we gained interest in the topic of growing neural networks. Intuitively, this problem has a similar part, in which we want to add new neurons or weights. In the case of Large Language Models, the topic is mentioned in [Gopher]. The authors describe that for their experiments, copying existing neurons was the best strategy. We have also tried this strategy, but without positive results.\nStarając się wyjaśnić nasze dotychczasowe problemy, zwróciliśmy uwagę na dyskretną naturę naszej techniki, as opposed to the continuous landscape of training/optimizers. To change this, we have modified our strategy to gradually change the value by linear interpolation, according to the rule\n&lt;latex ze wzorkiem; może jakiś plot z naszymi górkami&gt;,\nwhere was frozen and trainable. We have noticed that this way we were able to make training loss dynamics smoother, but still without any positive effect.\nIn general, we couldn’t beat the baseline in terms of performance."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#immunity",
    "href": "posts/neuron_recycling/index.html#immunity",
    "title": "Neuron Recycling",
    "section": "Immunity",
    "text": "Immunity\nAnother thing we tried to make reinitialization work was Immunity. The idea here is to encourage diverse recycling by making each recycled neuron immune to further recycling for some predefined number of steps. We hypothesized that a reinitialized neuron needs some time to grow, but in our initial setting, the neuron is recycled before enough growth happens, keeping the smaller neurons in a vicious cycle of periodically reoccurring reinitialization. Unfortunately, in our experiments, the reinitialized neurons failed to grow even if given immunity. At the same time immunity of the small neurons lead to recycling of the large neurons, hurting the model’s performance."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#modifying-reinitialization-distrin",
    "href": "posts/neuron_recycling/index.html#modifying-reinitialization-distrin",
    "title": "Neuron Recycling",
    "section": "Modifying reinitialization distrin",
    "text": "Modifying reinitialization distrin\n&lt;graph in which initial recycling are not visible, but later once show it hurts performance&gt;\nAt this point, we hypothesized that coming back to the initial distribution may not be the optimal choice, as weights of the neurons evolve while they are trained. The next idea we wanted to experiment with was simply sampling from the distribution that occurred across the entire layer at any given moment. Our approach was straightforward: we randomly selected from all the weights in the entire matrix. Here again, we noted the impact of our technique, but it was only when we conducted such intensive recycling that performance deteriorated. ^ Tu opisać reinicjalizację z dystrybucją z momentu recyklingu\n\nAt this stage of our project, we gained interest in the topic of growing neural networks. Intuitively, this problem has a similar part, in which we want to add new neurons or weights. In the case of Large Language Models, the topic is mentioned in [Gopher]. The authors describe that for their experiments, copying existing neurons was the best strategy. We have also tried this strategy, but without positive results.\nStarając się wyjaśnić nasze dotychczasowe problemy, zwróciliśmy uwagę na dyskretną naturę naszej techniki, as opposed to the continuous landscape of training/optimizers. To change this, we have modified our strategy to gradually change the value by linear interpolation, according to the rule\n&lt;latex ze wzorkiem; może jakiś plot z naszymi górkami&gt;,\nwhere was frozen and trainable. We have noticed that this way we were able to make training loss dynamics smoother, but still without any positive effect.\nIn general, we couldn’t beat the baseline in terms of performance."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#modifying-reinitialization-weights-distribution",
    "href": "posts/neuron_recycling/index.html#modifying-reinitialization-weights-distribution",
    "title": "Neuron Recycling",
    "section": "Modifying reinitialization weights distribution",
    "text": "Modifying reinitialization weights distribution\nAs we have pointed out before, magnitude and weight distribution drifts away from the initial distribution as the training progresses. However, during our initial attempts, we initialized the weights sampling from the initial distribution. To fix this issue, we decided to try out another weight sampling technique. A feed-forward layer consists of two matrices. Each time a neuron is reinitialized, the corresponding row and column in the matrices are filled with new (reinitialized) weights. The new technique, when replacing the weights, used the normal distribution with mean and standard deviation equal to the mean and standard deviation of all the weights in the respective matrix. This approach, like immunity, eliminated the vicious cycle. However, this process introduced a lot of noise with adverse effect on the model’s loss."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#inverse-weight",
    "href": "posts/neuron_recycling/index.html#inverse-weight",
    "title": "Neuron Recycling",
    "section": "Inverse Weight",
    "text": "Inverse Weight\nWhile working towards the main goal of the project, we started investigating the distribution of neuron magnitudes during the training [link do sekcji z blogposta]. We noticed that the magnitude distribution is quite uneven - a large percentage of neurons remains small, and the distribution is right-skewed. Since the goal of our project was to reduce the number of low-quality, i.e., small neurons, we came up with a pretty risky solution: inverse weight decay. The idea was to introduce an additional loss term that would encourage neuron growth. The general equation for that loss is:  Since this idea is quite similar to weight decay, we decided not to optimize this term with Adam, but to split it from the task loss and optimize it using simple gradient descent - a similar technique is used in AdamW to incorporate weight decay loss term. Since we weren;c\n&lt;plot, że iwd zmienia dystrybucję magnitude&gt; &lt;wariacje nt. Plotu ze strzałkami tłumaczące różne opcje w immunity&gt;"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#midpoint-loss",
    "href": "posts/neuron_recycling/index.html#midpoint-loss",
    "title": "Neuron Recycling",
    "section": "Midpoint Loss",
    "text": "Midpoint Loss\nWhile working towards the main goal of the project, we started investigating the distribution of neuron magnitudes during the training [link do sekcji z blogposta]. We noticed that the magnitude distribution is quite uneven - a large percentage of neurons remains small, and the distribution is right-skewed. Since the goal of our project was to reduce the number of low-quality, i.e., small neurons, we came up with a pretty risky solution: Midpoint Loss. The idea was to introduce an additional loss term that would encourage neuron growth and ``even-ness’’ of the magnitude distribution. The general equation for the midpoint loss is:\n\\[ Loss = \\sum_{l = 1}^{L} \\sum_{n = 1}^{dff} dist(M_{l,n}, stop\\_grad(midpoint(M_{l,*}))), \\] where:\n\n\\(M_{l,n}\\) -magnitude of then-th neuron in the l-th layer \\(dist\\) - some distance function, typically\\(l_1\\),\\(l_2\\) \\(midpoint\\) -mean or median. Median can be used instead of mean because of itsrobustness with respect\n\nSince this idea is quite similar to weight decay, we decided not to optimize this term with Adam, but to split it from the task loss and optimize it using simple gradient descent - a similar technique is used in AdamW to incorporate weight decay loss term. Since we weren;c\n&lt;plot, że iwd zmienia dystrybucję magnitude&gt; &lt;wariacje nt. Plotu ze strzałkami tłumaczące różne opcje w immunity&gt;"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#tangent---midpoint-loss",
    "href": "posts/neuron_recycling/index.html#tangent---midpoint-loss",
    "title": "Neuron Recycling",
    "section": "Tangent - Midpoint Loss",
    "text": "Tangent - Midpoint Loss\nWhile working towards the main goal of the project, we started investigating the distribution of neuron magnitudes during the training [link do sekcji z blogposta]. We noticed that the magnitude distribution is quite uneven - a large percentage of neurons remains small, and the distribution is right-skewed. Since the goal of our project was to reduce the number of low-quality, i.e., small neurons, we came up with a pretty risky solution: Midpoint Loss. The idea was to introduce an additional loss term that would encourage neuron growth and ``even-ness’’ of the magnitude distribution. The general equation for the midpoint loss is:\n\\[ Loss = \\sum_{l = 1}^{L} \\sum_{n = 1}^{dff} dist(M_{l,n}, stop\\_grad(midpoint(M_{l,*}))), \\] where:\n\n\\(M_{l,n}\\) -magnitude of then-th neuron in the l-th layer \\(dist\\) - some distance function, typically\\(l_1\\),\\(l_2\\) \\(midpoint\\) -mean or median. Median can be used instead of mean because of itsrobustness with respect\n\nSince this idea is quite similar to weight decay, we decided not to optimize this term with Adam, but to split it from the task loss and optimize it using simple gradient descent - a similar technique is used in AdamW to incorporate weight decay loss term. Since we weren;c\n&lt;plot, że iwd zmienia dystrybucję magnitude&gt; &lt;wariacje nt. Plotu ze strzałkami tłumaczące różne opcje w immunity&gt;"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#copying-existing-neurons",
    "href": "posts/neuron_recycling/index.html#copying-existing-neurons",
    "title": "Neuron Recycling",
    "section": "Copying existing neurons",
    "text": "Copying existing neurons\nAt this stage of our project, we gained interest in the topic of growing neural networks. Intuitively, this problem has a similar part, in which we want to add new neurons or weights. In the case of Large Language Models, the topic is mentioned in [Gopher]. The authors describe that for their experiments, copying existing neurons was the best strategy. We have also tried this strategy, but without positive results."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#model-and-training-setup",
    "href": "posts/neuron_recycling/index.html#model-and-training-setup",
    "title": "Neuron Recycling",
    "section": "Model and training setup",
    "text": "Model and training setup\nOur model is BERT blah blah…\n\nTransformer  Transformer is the leading modern neural network architecture. To keep things concise, we refer you to  if you want to learn more about it. The most important thing in this blogpost is that a Transformer consists of many blocks stacked on top of each other, with each of the blocks containing multi-head attention mechanism and a feed-forward layer. This blogpost focuses on recycling neurons in the feed-forward layer. &lt;dwa słowa, dlaczego atakujemy tę część a nie np atencję&gt;"
  },
  {
    "objectID": "posts/neuron_recycling/index.html#important-definitions",
    "href": "posts/neuron_recycling/index.html#important-definitions",
    "title": "Neuron Recycling",
    "section": "Important definitions",
    "text": "Important definitions\n\nNeuron  Neurons are the basic building blocks of artificial neural networks. A neuron consists of some weights going “into” the neuron (\\(w_{in}\\text{'s}\\)), an activation function (we use ReLU), and the weights going “out” of the neuron (\\(w_{out}\\text{'s}\\)). Technically speaking, the neurons’ weights are a column and a row of two matrices. &lt;coś o tym, że u nas zawsze są dwa bloki liniowe + napisać o macierzach&gt;\nMagnitude  The magnitude of a neuron is given as \\(M=\\sqrt{\\sum{w_{in}^2} \\sum{w_{out}^2}}\\). The magnitude of a weight is simply its absolute value."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#pruning",
    "href": "posts/neuron_recycling/index.html#pruning",
    "title": "Neuron Recycling",
    "section": "Pruning",
    "text": "Pruning\nPruning is a technique used to induce sparsity and decrease the parameter count in a neural network. It is basically a fancy name for deleting the least important neurons (structured pruning) or weights (unstructured pruning). A typical implementation realizes this by either multiplying the output of the deleted neurons by 0 or setting the weights of the neuron to 0. A widely-used proxy for the importance of a neuron or weight is its magnitude. You may find it counterintuitive, but we can even remove the whole FF Layer and the model will still work. This is because FF can be approximated by Attention. Below is a plot with pruning.\n\n\n\n\n                                                    \n\n\nAs you can see, pruning is getting works just in step 35k, and no FF is slightly better in the end."
  },
  {
    "objectID": "posts/neuron_recycling/index.html#smooth-recycling",
    "href": "posts/neuron_recycling/index.html#smooth-recycling",
    "title": "Neuron Recycling",
    "section": "Smooth recycling",
    "text": "Smooth recycling\nStarając się wyjaśnić nasze dotychczasowe problemy, zwróciliśmy uwagę na dyskretną naturę naszej techniki, as opposed to the continuous landscape of training/optimizers. To change this, we have modified our strategy to gradually change the value by linear interpolation, according to the rule\n&lt;latex ze wzorkiem; może jakiś plot z naszymi górkami&gt;,\nwhere was frozen and trainable. We have noticed that this way we were able to make training loss dynamics smoother, but still without any positive effect.\n\n\n\n\n                                                    \n\n\nIn general, we couldn’t beat the baseline in terms of performance."
  }
]